{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition\n",
    "\n",
    "**States:** For now, I think that it should also be stateless, since all the states I can think of are: \n",
    "- *posture quality:* (poor posture triggers the agent to make an action anyway, so it should be implemented as an iteration itself), \n",
    "- *time of the day:* since the experiment is not long, it can be just an input to the algorithm, for example to have a larger number of iterations\n",
    "- *duration of usage:* could be implemented as $\\epsilon$ the temperature for exploration vs. exploitation...?\n",
    "- *last intervention/outcome:* ?? I don't even know how would this make difference, perhaps in the transition dynamics...\n",
    "- *number of times the experiment has been conducted on that user:* also before the actual experiment???\n",
    "should all of these parameters actually have an impact on those probabilities?\n",
    "BUT, STATELESS IS ALSO A VERY SIMPLE SOLUTION... in this problem states then wouldn't be dependant on the actions that we take and that is what is confusing to me... \n",
    "\n",
    "states should be for example: head tilted to left, too close,...\n",
    "the probabilities should change over time or whatever, and depend on each state too...\n",
    "transition dynamics, what is a probability from going from one state to other etc...\n",
    "all the states should be w.r.t to what we can actually measure, so because it is only tilt or too close/not, that is what the states should be refllective of\n",
    "\n",
    "what is one learning step of our learning? to us i think event-based, when we detect bad posture...\n",
    "\n",
    "create a class for a user and all his attributes?\n",
    "\n",
    "how do we plan to deal with exploration/explotation balance...?\n",
    "\n",
    "Proposal: should the states maybe be EA and EC and actions to transition to the other type of intervention or to remain on the same one?\n",
    "\n",
    "**Actions:** Actions can take value of either EC - error correction or EA - error amplification.\n",
    "\n",
    "**Reward system:** Either -1 (posture not corrected) or +1 (corrected) - how do we collect the actual reward in an iteration, what do we observe?\n",
    "\n",
    "**Event-driven iterations:** Detection in the change of posture from good to poor is an event that triggers the agent to make an action. In the code, that is defined with a loop with max number of iterations. Should it depend on the user though? For example, we have some general information collected about the user, whether he/she has bad posture generally, what time of the day it is (if it's evening, the subject is most likely tired and has a bad posture - so interventions are triggered much more frequently, leading to more iterations overall).\n",
    "\n",
    "**Non-episodic learning:** We start from Q values set to zero each time, this means that we don't learn anything from experiment to experiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposal:\n",
    "\n",
    "### *Environment: (dependent on the user)*\n",
    "\n",
    "**States:** two dimensions: **tilt** and **closeness** to the screen. \n",
    "- Along the **tilt** dimension, we have discretized the head roll angle to three possible values: *left*, *normal* and *right*. \n",
    "- Along the **closeness** dimension (*y* coordinate from the tablet) we can either have a *normal* distance or *too close* (below a certain threshold) - check in the paper for exact values.  \n",
    "\n",
    "This forms a 2x3 state space, where the only valid posture that does not trigger the intervention is (normal, normal). The thing is that then, $p_{EC}$ and $p_{EA}$ should be incorporated in the transition matrix as the probability of getting from some state to the *normal* state (the probability of the intervention actually working, from each state and for each action/intervention). \n",
    "\n",
    "<img src=\"states.png\" alt=\"state space\" width=\"400\"/>\n",
    "\n",
    "The question is: How to define iterations then? Is that the possibility of going from a normal state to other states? We need an action of doing nothing, and a high probability of going from the normal state to others,... while also that probability should get higher as the experiment goes on...\n",
    "The problem also is the fact that a person can move from state to state regardless of the fact that our agent has taken an action or not... That is especially the case if the state is normal - our agent might learn to do nothing, but how do we impose that it actually goes to some other state, is it by transition matrix and a possibility of it going to some other state even though from neutal doing nothing should take you to a neutral state? Should a reward then be ending up in normal state +1, ending up in some other state -1?? \n",
    "\n",
    "**Actions:** \n",
    "\n",
    "EA - Error Amplification, EC - Error Correction, or DO NOTHING?\n",
    "\n",
    "**Reward system:**\n",
    "\n",
    "Either -1 (posture not corrected) or +1 (corrected, i.e. from a bad posture state transitioned to normal). Add new rewards, for example 0 if the user just naturally falls into bad posture from 4?? MAKE A REWARD MATRIX!\n",
    "\n",
    "### Additional remarks:\n",
    "\n",
    "Since in paper they say: \"We cannot draw a conclusive conclusion about whether children's understanding of the intervention strategy influences the effectiveness of the system. Further experiments are still required.\", maybe for now we do not simulate a single user doing the experiment multiple times. If we end up deciding to do so, then we have to create an agent for every user, which will learn from experiment to experiment, that won't be non-episodic learning anymore... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Keep using keras-2 (tf-keras) rather than keras-3 (keras).\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tf_agents.environments as tf_env\n",
    "import tf_agents.specs as tf_specs\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from utils.mdp_solver import MDPsolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For now this is a stateless implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningEnv():\n",
    "    # Encode action:\n",
    "    # EC = 0\n",
    "    # EA = 1\n",
    "    # DO NOTHING = 2\n",
    "\n",
    "\n",
    "    def __init__(self, transition_model):\n",
    "        # Defining the state space\n",
    "        self._num_states = 6\n",
    "        # Defining the action space\n",
    "        self._num_actions = 3\n",
    "        # Discount factor\n",
    "        self._gamma = 0.99\n",
    "\n",
    "        # Decaying factor for DO NOTHING action in transition matrix\n",
    "        self._transition_decay = 0.99\n",
    "\n",
    "        # User specifications - transition matrix\n",
    "        self._T = transition_model # shape = (num_actions, num_states, num_states)\n",
    "\n",
    "        # Reward system matrix (num_actions, num_states, num_states)\n",
    "        self.reward = np.array([[[-1,0.-0.5,-1,-0.5,1,-0.5],[-1,-0.5,-1,-0.5,1,-0.5],[-1,-0.5,-1,-0.5,1,-0.5],[-1,-0.5,-1,-0.5,1,-0.5],[-1,-1,-1,-1,0,-1],[-1,-0.5,-1,-0.5,1,-0.5]],     # EC\n",
    "                                [[-1,0.-0.5,-1,-0.5,1,-0.5],[-1,-0.5,-1,-0.5,1,-0.5],[-1,-0.5,-1,-0.5,1,-0.5],[-1,-0.5,-1,-0.5,1,-0.5],[-1,-1,-1,-1,0,-1],[-1,-0.5,-1,-0.5,1,-0.5]],     # EA\n",
    "                                [[-1,-1,-1,-1,0,-1],[-1,-1,-1,-1,0,-1],[-1,-1,-1,-1,0,-1],[-1,-1,-1,-1,0,-1],[0,0,0,0,1,0],[-1,-1,-1,-1,0,-1]]])    # DO_NOTHING\n",
    "        self.current_state = 4 # the default (normal,normal) state\n",
    "        self._step_count = 0\n",
    "        self._total_reward = 0.0\n",
    "\n",
    "    def _decay_transitions(self):\n",
    "        for i in range(self._num_states):\n",
    "            decay_update = self._T[2][i, i] * self._transition_decay\n",
    "            decay_update = decay_update if decay_update > 0.4 else 0.4\n",
    "            self._T[2][i, i] = decay_update\n",
    "            self._T[2][i] /= np.sum(self._T[2][i])\n",
    "\n",
    "    def _step(self, action):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        action - chosen action of the step with eps-greedy exploration\n",
    "        alpha - a.k.a. learning_rate\n",
    "        \"\"\"\n",
    "        # TODO: integrate with the physical environment here\n",
    "\n",
    "        # To which state next does the action take us?\n",
    "        new_state = np.random.choice(np.arange(self._num_states), p=self._T[action][self.current_state])\n",
    "\n",
    "        # Receiving the reward only if the new state is the (normal, normal) state\n",
    "        reward = self.reward[action, self.current_state, new_state]\n",
    "\n",
    "        self.current_state = new_state\n",
    "\n",
    "        self._step_count += 1\n",
    "        self._total_reward += reward\n",
    "\n",
    "        self._decay_transitions()\n",
    "\n",
    "        return reward, self.current_state, new_state  # KAKO DA VRATIMO OVO SVE??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsGreedyAgent:\n",
    "    def __init__(self, num_actions, num_states, explore_rate = 1.0): #JEL JE OVO OK??? \n",
    "        self.num_actions = num_actions\n",
    "        self.num_states = num_states\n",
    "\n",
    "         # Initialization of Q and V values \n",
    "        self.Q = np.zeros(shape=(num_states, num_actions), dtype=float)\n",
    "        self.V = np.zeros(shape=(num_states,)) # da li je ovo ok???\n",
    "        self.N = np.zeros((num_states, num_actions))\n",
    "\n",
    "        self.action_counts = [0] * num_actions\n",
    "        self.step_counts = 0\n",
    "        self.explore = explore_rate  \n",
    "        self.reward_history = []\n",
    "\n",
    "    def select_action(self, env:QLearningEnv):\n",
    "        # Should be selected on the basis of epsilon greedy from the current state\n",
    "\n",
    "        explore = np.random.binomial(2, p=self.explore)\n",
    "        if explore:\n",
    "            # Exploration: With probability epsilon take a random action, an index of an action\n",
    "            a = np.random.choice(np.arange(self.num_actions))\n",
    "        else:\n",
    "            # Exploitation: With probability 1 - epsilon take one of the optimal actions for the current state\n",
    "            a = np.argmax(self.Q[env.current_state,:])\n",
    "\n",
    "        return a\n",
    "\n",
    "    def update_estimates(self, action, reward, state, new_state, alpha):\n",
    "        \n",
    "        \"\"\"\n",
    "        Updates the values of action counts, step counts, reward history etc.\n",
    "\n",
    "        Inputs:\n",
    "        action - action taken in the current step\n",
    "        reward - reward collected while taking the step when interacting with the environment\n",
    "        alpha - \n",
    "        \"\"\"\n",
    "        \n",
    "        # Interaction with the environment - collecting reward \n",
    "        self.reward_history.append(reward)\n",
    "\n",
    "        self.N[state, action] += 1\n",
    "        alpha = 0.5 / (self.N[state, action] + 1) ** 0.75\n",
    "\n",
    "        # Update Q according to the algorithm\n",
    "        # self.Q[state, action] = (1-alpha) * self.Q[state,action] + alpha * (reward + 0.99*self.V[new_state])\n",
    "        self.Q[state, action] = (1 - alpha) * self.Q[state, action] + alpha * (reward + 0.99*np.max(self.Q[new_state, :]))\n",
    "\n",
    "        # Update V as the Q-value of the optimal actions for the current state\n",
    "        self.V[state] = np.max(self.Q[state, :])\n",
    "        \n",
    "        self.action_counts[action] += 1\n",
    "        self.step_counts += 1\n",
    "        \n",
    "\n",
    "\n",
    "    def get_current_average_reward(self):\n",
    "        return np.mean(self.reward_history)\n",
    "    \n",
    "    def get_cumulative_reward(self):\n",
    "        return np.sum(self.reward_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_simulation(transition_model, num_iterations = 500, explore_rate = 2.0, alpha = 0.5):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "\n",
    "  user_model_vec:\n",
    "  num_iterations: maximal number of iterations, in our problem this refers to the number of times the posture becomes poor, \n",
    "  i.e. number of interventions - should be modified to be dependant on the user and its attributes...\n",
    "  explore_rate: maybe modify to be dependant on the period of the day...? explore more if it is evening and more fatigue...?\n",
    "\n",
    "  Outputs:\n",
    "\n",
    "  average_rewards:\n",
    "  rmse:\n",
    "  reward_history:\n",
    "\n",
    "  \"\"\"\n",
    "  # Create the environment\n",
    "  \n",
    "  env = QLearningEnv(transition_model)\n",
    "\n",
    "  # Create the epsilon greedy agent\n",
    "  agent = EpsGreedyAgent(env._num_actions, env._num_states, explore_rate)\n",
    "\n",
    "  average_rewards = []\n",
    "  rmse = []\n",
    "\n",
    "  # Training loop\n",
    "  for _ in range(num_iterations):\n",
    "      # Take one step \n",
    "      action = agent.select_action(env)\n",
    "      reward, state, new_state = env._step(action)\n",
    "      agent.update_estimates(action, reward, state, new_state, alpha)\n",
    "\n",
    "      # print(env._T[2])\n",
    "      # print()\n",
    "\n",
    "      # Logs for plotting\n",
    "      average_rewards.append(agent.get_current_average_reward()) # should we plot current average reward or current reward that is collected??\n",
    "      \n",
    "\n",
    "  # Evaluate the agent\n",
    "  if False:\n",
    "    total_reward = 0.0\n",
    "    for _ in range(10):  # Test for 10 episodes\n",
    "        time_step = env.reset()\n",
    "        while not time_step.is_last():\n",
    "            action = agent.select_action()\n",
    "            time_step = env.step(action)\n",
    "            total_reward += time_step.reward\n",
    "    print(f'Average Reward of 10 episodes: {total_reward / 10 / 1000}')\n",
    "\n",
    "  return average_rewards, rmse, agent.reward_history, agent.Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation on one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05405405 0.05405405 0.16216216 0.10810811 0.40540541 0.21621622]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.1,0.1,0.3,0.2,0.75,0.4])\n",
    "a = a/np.sum(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.51581192 -6.51404657 -6.51402303]\n",
      " [-4.9592584  -4.96153263 -4.97337272]\n",
      " [-6.27457118 -6.27481806 -6.27350716]\n",
      " [-4.58349819 -4.58471467 -4.59957712]\n",
      " [13.81951533 13.86881109 14.23385254]\n",
      " [-4.66590463 -4.68484737 -4.66847498]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fix random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Simulating a user with a transition model\n",
    "# for EA, for the normal state, we should put high probability that the state would end up in bad posture? to encourage the system to do nothing...\n",
    "# but what foe EC since it would probably enlarge the text?\n",
    "transition_matrix = np.array([\n",
    "    [\n",
    "        [0.2, 0.025, 0.025, 0.025, 0.7, 0.025],\n",
    "        [0.025, 0.1, 0.025, 0.025, 0.8, 0.025],\n",
    "        [0.025, 0.025, 0.2, 0.025, 0.7, 0.025],\n",
    "        [0.025, 0.025, 0.025, 0.1, 0.8, 0.025],\n",
    "        [0.02, 0.02, 0.02, 0.02, 0.9, 0.02],\n",
    "        [0.025, 0.025, 0.025, 0.025, 0.8, 0.1]\n",
    "    ],\n",
    "    [\n",
    "        [0.1, 0.025, 0.025, 0.025, 0.8, 0.025],\n",
    "        [0.025, 0.1, 0.025, 0.025, 0.8, 0.025],\n",
    "        [0.025, 0.025, 0.1, 0.025, 0.8, 0.025],\n",
    "        [0.025, 0.025, 0.025, 0.1, 0.8, 0.025],\n",
    "        [0.08, 0.08, 0.08, 0.08, 0.6, 0.08],\n",
    "        [0.025, 0.025, 0.025, 0.025, 0.8, 0.1]\n",
    "    ],\n",
    "    [\n",
    "        [0.9, 0.02, 0.02, 0.02, 0.02, 0.02],\n",
    "        [0.02, 0.9, 0.02, 0.02, 0.02, 0.02],\n",
    "        [0.02, 0.02, 0.9, 0.02, 0.02, 0.02],\n",
    "        [0.02, 0.02, 0.02, 0.9, 0.02, 0.02],\n",
    "        [0.02, 0.02, 0.02, 0.02, 0.9, 0.02],\n",
    "        [0.02, 0.02, 0.02, 0.02, 0.02, 0.9],\n",
    "    ]\n",
    "])\n",
    "\n",
    "average_rewards, rmse, reward_history, Q = user_simulation(transition_model = transition_matrix, explore_rate=0.1, alpha=0.7, num_iterations=50000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(average_rewards)\n",
    "plt.ylabel('Average Reward')\n",
    "plt.xlabel('Number of Iterations')\n",
    "\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-51.68087392, -51.43266475, -55.6204871 ],\n",
       "       [-51.43266475, -51.43266475, -55.6204871 ],\n",
       "       [-51.68087392, -51.43266475, -55.6204871 ],\n",
       "       [-51.43266475, -51.43266475, -55.6204871 ],\n",
       "       [-53.68445558, -54.42908309, -48.92550143],\n",
       "       [-51.43266475, -51.43266475, -55.6204871 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = QLearningEnv(transition_matrix)\n",
    "solver = MDPsolver(env)\n",
    "solver.value_iteration()\n",
    "solver.q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforcement_ass1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
